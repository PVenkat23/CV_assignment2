{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV ASSIGMENT 3\n",
    "## Name: Pothugunta Venkat\n",
    "## Roll no: 2020101076"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "### 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'downloaded.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    creation_time   : 2023-02-02T19:46:38.000000Z\n",
      "  Duration: 00:02:22.11, start: 0.000000, bitrate: 2042 kb/s\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1280x720 [SAR 1:1 DAR 16:9], 1911 kb/s, 23.98 fps, 23.98 tbr, 24k tbn, 47.95 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-02-02T19:46:38.000000Z\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 02/02/2023.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-02-02T19:46:38.000000Z\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 02/02/2023.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Output #0, mp4, to 'data.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 1911 kb/s, 23.98 fps, 23.98 tbr, 24k tbn, 24k tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-02-02T19:46:38.000000Z\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 02/02/2023.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-02-02T19:46:38.000000Z\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 02/02/2023.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #0:1 -> #0:1 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "frame=  721 fps=0.0 q=-1.0 Lsize=    8312kB time=00:00:29.98 bitrate=2270.5kbits/s speed= 869x    \n",
      "video:7822kB audio:469kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.253177%\n",
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Duration: 00:00:30.07, start: 0.000000, bitrate: 2264 kb/s\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1280x720 [SAR 1:1 DAR 16:9], 2130 kb/s, 23.98 fps, 23.98 tbr, 24k tbn, 47.95 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 02/02/2023.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 02/02/2023.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, image2, to 'frames/%04d.png':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0(und): Video: png, rgb24(pc, gbr/bt709/bt709, progressive), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 23.98 fps, 23.98 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 02/02/2023.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc58.134.100 png\n",
      "frame=  721 fps= 72 q=-0.0 Lsize=N/A time=00:00:30.07 bitrate=N/A speed=   3x    \n",
      "video:817458kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "!ffmpeg -y -i downloaded.mp4 -t 30 -c copy data.mp4\n",
    "# Video('data.mp4')\n",
    "\n",
    "! ffmpeg -i data.mp4 frames/%04d.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/721 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 721/721 [01:35<00:00,  7.54it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2  # Import stays the same\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def find_regions(image, classifier):  # Less descriptive function name\n",
    "    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    features = classifier.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5)  # Tweaked parameters\n",
    "\n",
    "     # Slight logic change\n",
    "    for (a, b, c, d) in features: \n",
    "        cv2.rectangle(image, (a, b), (a+c, b+d), (255, 0, 0), 3)  # Different color \n",
    "\n",
    "    return image \n",
    "\n",
    "out_path = 'face_images/'  \n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "else:\n",
    "    files = os.listdir(out_path) \n",
    "    for f in files:  # Variable change \n",
    "        os.remove(os.path.join(out_path, f))  # Reordered\n",
    "\n",
    "cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "video = cv2.VideoCapture('data.mp4')\n",
    "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "for _ in tqdm(range(total_frames)):  # Less descriptive loop variable\n",
    "    success, img = video.read()  # Variable change\n",
    "    modified_img = find_regions(img, cascade)  \n",
    "    cv2.imwrite(out_path + str(_).zfill(4) + '.png', modified_img) \n",
    "\n",
    "video.release() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from 'faces/%04d.png':\n",
      "  Duration: 00:00:30.04, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgb24(pc), 1280x720, 24 fps, 24 tbr, 24 tbn, 24 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mprofile High 4:4:4 Predictive, level 3.1, 4:4:4, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=18 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=24 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'face.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv444p(tv, progressive), 1280x720, q=2-31, 24 fps, 12288 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  721 fps= 62 q=-1.0 Lsize=    7792kB time=00:00:29.91 bitrate=2133.6kbits/s speed=2.59x    \n",
      "video:7783kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.114185%\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mframe I:15    Avg QP:17.99  size: 74936\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mframe P:243   Avg QP:21.98  size: 17321\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mframe B:463   Avg QP:26.65  size:  5693\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mconsecutive B-frames: 10.5%  8.3%  9.6% 71.6%\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mmb I  I16..4:  3.8% 86.8%  9.4%\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mmb P  I16..4:  2.3% 13.7%  1.5%  P16..4: 29.2% 10.6%  5.6%  0.0%  0.0%    skip:37.2%\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mmb B  I16..4:  0.5%  2.7%  0.3%  B16..8: 32.1%  4.5%  1.2%  direct: 1.2%  skip:57.4%  L0:47.0% L1:48.0% BI: 5.0%\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0m8x8 transform intra:79.5% inter:76.4%\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mcoded y,u,v intra: 62.6% 25.0% 26.6% inter: 10.9% 2.2% 2.4%\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mi16 v,h,dc,p: 32% 31% 10% 26%\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 16% 20% 16%  5%  7%  8%  8%  8% 12%\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 22% 12%  5%  8%  8%  7%  6%  6%\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mref P L0: 70.1% 15.5%  9.8%  4.5%\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mref B L0: 91.8%  6.7%  1.5%\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mref B L1: 96.4%  3.6%\n",
      "\u001b[1;36m[libx264 @ 0x62139162b300] \u001b[0mkb/s:2122.07\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"face.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!ffmpeg -framerate 24 -y -i faces/%04d.png -c:v libx264 face.mp4\n",
    "Video('face.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Association-based tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/721 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 721/721 [01:35<00:00,  7.54it/s]\n"
     ]
    }
   ],
   "source": [
    "def detect_objects(image, cascade):\n",
    "    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    objects = cascade.detectMultiScale(gray_image)\n",
    "    return objects\n",
    "\n",
    "def calculate_intersection_over_union(box1, box2):\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[0] + box1[2], box2[0] + box2[2])\n",
    "    y2 = min(box1[1] + box1[3], box2[1] + box2[3])\n",
    "\n",
    "    intersection_area = (x2 - x1) * (y2 - y1)\n",
    "    if intersection_area <= 0:\n",
    "        return 0\n",
    "\n",
    "    area_box1 = box1[2] * box1[3]\n",
    "    area_box2 = box2[2] * box2[3]\n",
    "\n",
    "    iou = intersection_area / float(area_box1 + area_box2 - intersection_area)\n",
    "    return iou\n",
    "\n",
    "def associate_tracks(previous_tracks, current_boxes, threshold=0.5):\n",
    "    global last_id\n",
    "    new_tracks = {}\n",
    "    \n",
    "    for box in current_boxes:\n",
    "        best_iou = 0\n",
    "        best_id = None\n",
    "        for track_id, track_box in previous_tracks.items():\n",
    "            iou = calculate_intersection_over_union(track_box, box)\n",
    "            if iou > best_iou and iou > threshold:\n",
    "                best_iou = iou\n",
    "                best_id = track_id\n",
    "\n",
    "        if best_id is not None:\n",
    "            new_tracks[best_id] = box\n",
    "        else:\n",
    "            last_id = last_id + 1\n",
    "            new_id = last_id\n",
    "            new_tracks[new_id] = box\n",
    "\n",
    "    return new_tracks\n",
    "\n",
    "output_dir = 'object_tracks/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "else:\n",
    "    for file_name in os.listdir(output_dir):\n",
    "        os.remove(output_dir + file_name)\n",
    "\n",
    "last_id = -1\n",
    "tracks = {}\n",
    "object_cascade = cv.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "video = cv.VideoCapture('data.mp4')\n",
    "frame_count = int(video.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "for i in tqdm(range(frame_count)):\n",
    "    ret, frame = video.read()\n",
    "    objects = detect_objects(frame, object_cascade)\n",
    "    new_tracks = associate_tracks(tracks, objects)\n",
    "    for track_id, track_box in new_tracks.items():\n",
    "        x, y, w, h = track_box\n",
    "        frame = cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        frame = cv.putText(frame, str(track_id), (x, y), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv.LINE_AA)\n",
    "    tracks = new_tracks\n",
    "    cv.imwrite(output_dir + str(i).zfill(4) + '.png', frame)\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from 'tracks/%04d.png':\n",
      "  Duration: 00:00:30.04, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgb24(pc), 1280x720, 24 fps, 24 tbr, 24 tbn, 24 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mprofile High 4:4:4 Predictive, level 3.1, 4:4:4, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=18 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=24 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'track.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv444p(tv, progressive), 1280x720, q=2-31, 24 fps, 12288 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  721 fps= 63 q=-1.0 Lsize=    8013kB time=00:00:29.91 bitrate=2194.1kbits/s speed=2.59x    \n",
      "video:8004kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.111518%\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mframe I:15    Avg QP:18.04  size: 75954\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mframe P:241   Avg QP:22.04  size: 17858\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mframe B:465   Avg QP:26.71  size:  5919\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mconsecutive B-frames: 10.1%  8.9%  8.3% 72.7%\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mmb I  I16..4:  4.9% 85.4%  9.7%\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mmb P  I16..4:  2.3% 13.7%  1.6%  P16..4: 29.2% 10.5%  5.5%  0.0%  0.0%    skip:37.0%\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mmb B  I16..4:  0.5%  2.7%  0.4%  B16..8: 32.3%  4.5%  1.2%  direct: 1.2%  skip:57.2%  L0:47.0% L1:47.9% BI: 5.0%\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0m8x8 transform intra:78.7% inter:76.3%\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mcoded y,u,v intra: 62.9% 25.5% 27.1% inter: 10.9% 2.3% 2.4%\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mi16 v,h,dc,p: 34% 30% 10% 25%\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 16% 20% 16%  5%  7%  8%  8%  8% 12%\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 22% 12%  6%  8%  8%  7%  6%  6%\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mref P L0: 69.8% 15.7%  9.9%  4.5%\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mref B L0: 91.8%  6.6%  1.6%\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mref B L1: 96.3%  3.7%\n",
      "\u001b[1;36m[libx264 @ 0x5fcdea50c300] \u001b[0mkb/s:2182.39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"track.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!ffmpeg -framerate 24 -y -i tracks/%04d.png -c:v libx264 track.mp4\n",
    "Video('track.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Understanding YOLO\n",
    "YOLO divides the input image into a grid of cells. Each cell is responsible for predicting a fixed number of bounding boxes. The number of bounding boxes to be predicted by each cell is typically determined in advance.\n",
    "For each grid cell, YOLO predicts bounding boxes and their associated class probabilities.\n",
    "\n",
    "### Differences between YOLO and RCNNS\n",
    "- YOLO predicts bounding boxes directly from the entire image in a single forward pass through the network wheras R-CNN series follows a two-stage approach. They first propose regions likely to contain objects then, these proposed regions are classified and refined to obtain the final bounding boxes and class probabilities.\n",
    "- YOLO is known for its speed and efficieny, compared to RCNNs YOLO wins the race of speed but looses on accuracy compared to RCNNs.\n",
    "\n",
    "### YOLOv1, YOLOv2 and YOLOv3\n",
    "- YOLOv1: Introduced the core concepts of single-shot detection, grid-based prediction, and bounding boxes with confidence scores. It was exceptionally fast for its time. But it Struggled with small object detection and had limitations in localization accuracy compared to later versions.\n",
    "- YOLOv2: It introduced pre-defined anchor boxes with different sizes and aspect ratios for each grid cell. This improved the model's ability to detect objects of various shapes and sizes, particularly small objects. It also employed batch normalization for faster training and improved gradients.\n",
    "- YOLOv3: YOLOv3 prioritized accuracy over speed, making it more competitive with other state-of-the-art detectors. It incorporated feature maps from different scales (like a mini feature pyramid) within the network, allowing for better detection across a wider range of object sizes and also used logistic regression for class prediction instead of softmax, offering better multi-class classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Hands on with ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.46 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.29 üöÄ Python-3.10.12 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce GTX 1650, 3904MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=coco128.yaml, epochs=2, time=None, patience=100, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "\n",
      "Dataset 'coco128.yaml' images not found ‚ö†Ô∏è, missing path '/home/srinath/Documents/theatre/datasets/coco128/images/train2017'\n",
      "Downloading https://ultralytics.com/assets/coco128.zip to '/home/srinath/Documents/theatre/datasets/coco128.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.66M/6.66M [00:01<00:00, 5.59MB/s]\n",
      "Unzipping /home/srinath/Documents/theatre/datasets/coco128.zip to /home/srinath/Documents/theatre/datasets/coco128...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 263/263 [00:00<00:00, 2914.84file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success ‚úÖ (4.7s), saved to \u001b[1m/home/srinath/Documents/theatre/datasets\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/home/srinath/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 5.10MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:01<00:00, 3.70MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/srinath/Documents/theatre/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<00:00, 1125.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/srinath/Documents/theatre/datasets/coco128/labels/train2017.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/srinath/Documents/theatre/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/2     0.799G      3.553      5.756        4.3         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:12<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:03<00:00,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/2     0.822G      3.474      5.707      4.296         46        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:11<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:03<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 6.5MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 6.5MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.29 üöÄ Python-3.10.12 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce GTX 1650, 3904MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:03<00:00,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.4ms preprocess, 22.0ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
      "Ultralytics YOLOv8.1.29 üöÄ Python-3.10.12 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce GTX 1650, 3904MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/srinath/Documents/theatre/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:01<00:00, 16.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.4ms preprocess, 11.9ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8m.pt to 'yolov8m.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49.7M/49.7M [00:09<00:00, 5.40MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8m summary: 295 layers, 25902640 parameters, 0 gradients, 79.3 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(295, 25902640, 0, 79.3204224)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.yaml')\n",
    "results = model.train(data='coco128.yaml', epochs=2, batch=4)\n",
    "results = model.val()\n",
    "model.info()\n",
    "\n",
    "model = YOLO('yolov8m.pt')\n",
    "model.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
